# save_folder: './results/pcfNAT_bf16_ps=2[4x4]_heads=[16,4]_dim=256_winsize=[[wx3,0][wx4][wx3,0][wx4]]_groups=[8,4,2,1]_droppath=0.11_mfa=T_proj=1536_aam_m=0.2_s=32_sub=3_wd=1e-5_nowdkey_bs=256_augxn=2_sgd_warmcoslr_1e-4_0.5_1_9_seeds=2024/'
save_folder: './results/pcf_nat4x4/'

train_data_foler: '/mnt/data_ext4/voxceleb/voxceleb2/'
train_data_sub_fd: 'wav/'
musan_folder: '/mnt/data_ext4/musan/'
simulated_rirs_folder: '/mnt/data_ext4/RIRS_NOISES/simulated_rirs/'

sample_rate: 16000
train_part_seconds: 3
random_chunk: True
divide: True # Long audio will be sampled multiple times when divide is true
resample: [0.9,1.1] # null, [] # audio shift
spkers_num: 17982 # 5994*( 1+len(resample) )
num_workers: 8
batch_size: 256
batchxn: 2 # if>1: every sample in batch will be expanded into multiple: one without data augmentation, others with data augmentation
aug_prob: 0.5 # invalid when batchxn>1
spk_ids_fn: 'spk_ids.txt' # The file will be saved at this address
train_list_fn: 'train_list_slice_3s_shift.txt' # The file will be saved at this address
    
seed: 2024
__set_seed: !apply:public.Utils.set_random_seed [!ref <seed>]
device: cuda
feat_dim: 80
emb_size: 192
train_dtype: !name:torch.bfloat16
compile_mode: default # null, default, reduce-overhead, max-autotune

start_lr: 1e-4
max_lr: 0.5
end_lr: !ref <start_lr>
weight_decay: 1e-5
allow_no_weight_decay: True
warm_epochs: 1
decacy_epochs: 9
decacy_scheduler: 'CosineAnnealingLR' # 'CosineAnnealingLR', 'LinearLR', 'ExponentialLR'
    
compute_features: !new:models.Features.Fbank_preEmphasis
    n_mels: !ref <feat_dim>
    left_frames: 0
    right_frames: 0
    deltas: False
    
embedding_model: !new:models.PCF_NATransformer.PCF_NATransformer
    frames: 300
    patch_size: 2
    in_chans: !ref <feat_dim>
    output_emb_size: !ref <emb_size>
    embed_dim: 256
    depths: [4,4,4,4]
    num_heads: [[16,16,16,4], [16,16,16,16], [16,16,16,4], [16,16,16,16]]
    win_size: [[27,27,27,0],[27,27,27,27], [27,27,27,0], [27,27,27,27]]
    groups: [8,4,2,1]
    attn_drop: 0.
    drop: 0.
    drop_path_rate: 0.11
    mfa: True
    proj_channel: 1536
    asp: True
    poolnorm: True
    use_checkpoint: False
    dtype: !ref <train_dtype>

classifier: !new:models.SoftMaxLoss.ArcMarginSoftMaxLoss_SubCenters
    emb_size: !ref <emb_size>
    n_classes: !ref <spkers_num>
    m: 0.2
    s: 32.
    subcenters: 3

#opt_class: !name:torch.optim.Adam
#    lr: !ref <max_lr>
#    betas: (0.9, 0.999)
#    eps: 1e-08
#    weight_decay: !ref <weight_decay>

opt_class: !name:torch.optim.SGD
    lr: !ref <max_lr>
    momentum: 0.9
    nesterov: True
    weight_decay: !ref <weight_decay>

__set_seed2: !apply:public.Utils.set_random_seed [!ref <seed>]
